{"name":"Gnu-bwt-aligner","tagline":"See description below.","body":"h1. Introduction\r\n\r\nNew high-throughput sequencers are able to produce data at an unprecedented scale, while sequencing costs are in free fall. Primary data processing, which often includes mapping short reads onto a reference genome, is computationally very expensive. Recently, a variety of programs, many of them implementing Burrows-Wheeler Transform (BWT), have been developed for such task. Despite the efficiency of BWT, the general view is that new approaches will be necessary to cope with the increasing flood of sequencing data.\r\n\r\nHPG-BWT proposes two new approaches to BWT sequence mapping:\r\n\r\n* The first one takes advantage of CUDA GPGPU processors. We have implemented BTW on GPU, allowing alignments of up to one error. Also, we parallelised the input/output operations on the CPU and the GPU execution of the mapping process. Our experiments show that this heterogeneous and really cheap solution outperforms by 3x the conventional algorithms based only on CPU.\r\n\r\n* The second one is a CPU implementation of the inexact search with BWT. By using optimised branch and bound techniques for biological information the number of errors allowed is greatly increased. In the case of the human genome, we support 6 errors with no sensibility penalty and within a reasonable execution time and memory size. The search routine studies insertions, deletions and mismatches. Our solution outperforms by a factor of 8x other BWT-CPU solutions. Also, by reducing the sensibility in 5-10% the speed of the algorithm can be increased by a factor of 4x, allowing up to 7-10 errors analysis.\r\n\r\nh2. System Requirements\r\n\r\n* Hardware:\r\n**  64-bit x86-64 CPUs\r\n**  32GB of RAM for human genome index calculation (This will be reduced in the near future).\r\n**  The GPU test program requires two graphic cards, a more complete version is included in the HPG pipeline.\r\n**  The CPU RAM required for searching against the human genome with the CPU or GPU test programs depends on the suffix array compression ratio (S, R and O.desp), with compression ratio 32x it needs about 7GB. This compression does not affect the search algorithm but can affect the speed of seeded mapping when using the tool with an Smith-Watterman implementation.\r\n**  GPUs with at least 3GB of RAM are needed for the human genome.\r\n* Software:\r\n**  64-bit Linux system\r\n\r\nh2. Installation and datasets\r\n\r\nThe x86_64 binaries and the source files are \"here\":http://docs.bioinfo.cipf.es/projects/bwtgpu/documents/.\r\n\r\nThe instructions on how to execute the binaries can be found \"here\":http://docs.bioinfo.cipf.es/projects/bwtgpu/wiki.\r\n\r\nThe BWT indexes and datasets employed to measure the performance of this tool are availabe \"here\":https://www.dropbox.com/sh/k9xqljzchyztta8/g7sWOjcUic.\r\n\r\nWhen compiling the tools do not forget to check in the makefile that the preprocessor variables -DVECTOR_O_64BIT_COMPRESSION are present, in order to enable 32/64 bits vector O compression.\r\nThe preprocess program needs to activate OpenMP with -fopenmp also.\r\n\r\nBoth preprocess and search must have been compiled with the same options in order to use the generated index with the search tool.\r\n\r\n\r\nh2. Command line options\r\n\r\n\r\nh3. *preprocess*\r\n\r\n<pre>\r\n./preprocess reference_file output_directory ratio duplicate_reverse nucleotides\r\n</pre>\r\n\r\n> *reference_file*, input file, in FASTA format, containing the reference to be indexed (up to 6GB references are supported)\r\n\r\n> *output_directory*, existing directory where the index files will be stored\r\n\r\n> *ratio*, the compression ratio of suffix array and its inverse (S and R).\r\n\r\n> *duplicate_reverse*, if 1 concatenates de reverse strand genome and computes the double sized index to search reverse and strand at the same time (for the human genome check that you compile the code with the flag -DSA_64, at the moment this takes a lot of memory).\r\n\r\n> *nucleotides*, the nucleotides present in the reference, in order.\r\n\r\nFor example,\r\n<pre>\r\n./preprocess genome.fa index/ 8 0 ACGT\r\n</pre>\r\n\r\nwill index genome.fa and store the output files in directory \"index\", vectors S and R will be 8x compressed, the duplicate reverse will not be appended and the nucleotides encoding in this reference will be ACGT - 0123.\r\n\r\nThe preprocess command employs the algorithm and code proposed in \"Daisuke Okanohara, Kunihiko Sadakane. A Linear-Time Burrows-Wheeler Transform Using Induced Sorting. In Proc. of SPIRE, LNCS 5721, pp. 90-101, 2009\", hosted at https://code.google.com/p/csalib/downloads/list\r\n\r\nh3. *inexact_search*\r\n\r\n<pre>\r\n./inexact_search mappings_file index_dir output_file duplicate_reverse search_tree_size num_errors min_fragment nucleotides\r\n</pre>\r\n\r\n> *mappings_file* The file with the reads\r\n\r\n> *index_dir* The directory with the index files\r\n\r\n> *output_file*, file where the mappings found will be stored\r\n\r\n> *duplicate_reverse*, if 1 the index of the reference and the concatenated duplicate reverse was stored in *index_dir*.\r\n\r\n> *search_tree_size*, the search tree size used for the Breadth First Search exploration (an small value increases performance but decreases the sensitivity).\r\n\r\n> *num_errors*, the maximum number of errors allowed during the search.\r\n\r\n> *min_fragment*, the minimum fragment size used by the exploration bounding techniques (does not affect sensitivity but an small value decreases performance).\r\n\r\n> *nucleotides*, the nucleotides present in the reference, in order.\r\n\r\nFor example,\r\n<pre>\r\n./inexact_search drosophila.fa drosophila_dbwt found 0 10000 3 17 ACGT\r\n</pre>\r\n\r\nwill map reads in drosophila.fa using the preprocessed index in folder drosophila_dbwt, which does not include the reverse. The reads found will be stored in the file \"found\", with a search_tree_size of 10000 elements, allowing up to 3 errors and a minimum segment size of 17 nucleotides (for the human genome 30 is a good value). The nucleotides encoding in this reference will be ACGT - 0123.\r\n\r\nh3. *search_gpu*\r\n\r\n<pre>\r\n./search_gpu mappings_file index_dir output_file notfound_file num_errors nucleotides\r\n</pre>\r\n\r\n> *mappings_file* The file with the reads\r\n\r\n> *index_dir* The directory with the index files\r\n\r\n> *output_file*, file where the mappings found will be stored\r\n\r\n> *notfound_file*, file where the mappings not found will be stored\r\n\r\n> *num_errors*, the maximum number of errors allowed during the search (only 0 or 1).\r\n\r\n> *nucleotides*, the nucleotides present in the reference, in order.\r\n\r\nFor example,\r\n<pre>\r\n./search_gpu drosophila.fa drosophila_dbwt found notfound 1 ACGT\r\n</pre>\r\n\r\nwill map reads in drosophila.fa using the preprocessed index in folder drosophila_dbwt. The reads found will be stored in the file \"found\", the reads not found in file \"notfound\", allowing up to 1 errors. The nucleotides encoding in this reference will be ACGT - 0123.\r\n\r\nCurrently this is only a test program and it needs a configuration with two nvidia graphic cards in order to work. It does not support duplicate reference indexes at the moment.\r\n\r\nNotice also that in all the tools the encoding for the four bases should be indicated. For genomes with less bases please check the reverse strand functions in file \"search/csafm.c\", and please do not forget to call function init_replace_table when embedding the source code.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}